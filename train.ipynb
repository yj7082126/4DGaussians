{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '3,'\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "from pathlib import Path\n",
    "import random\n",
    "from argparse import ArgumentParser, Namespace\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "np.set_printoptions(suppress=True)\n",
    "from PIL import Image\n",
    "import lpips\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms as T\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "from gaussian_renderer import render\n",
    "from scene import Scene, GaussianModel, colmap_loader\n",
    "from scene.cameras import Camera\n",
    "from scene.colmap_loader import read_extrinsics_binary, read_intrinsics_binary\n",
    "from scene.multipleview_dataset import multipleview_dataset_kubric\n",
    "from scene.dataset_readers import sceneLoadTypeCallbacks, format_infos, getNerfppNorm, fetchPly, SceneInfo\n",
    "from scene.dataset import FourDGSdataset\n",
    "from utils.graphics_utils import focal2fov\n",
    "from utils.loss_utils import l1_loss\n",
    "\n",
    "def setup_seed(seed):\n",
    "     torch.manual_seed(seed)\n",
    "     torch.cuda.manual_seed_all(seed)\n",
    "     np.random.seed(seed)\n",
    "     random.seed(seed)\n",
    "     torch.backends.cudnn.deterministic = True\n",
    "\n",
    "setup_seed(6666)\n",
    "# torch.cuda.set_device(0)\n",
    "# torch.autograd.set_detect_anomaly(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Namespace(**{\n",
    "    \"sh_degree\": 3, \"source_path\": None, \"model_path\": None, \"images\": 'images', \"resolution\": -1,\n",
    "    \"white_background\": True, \"data_device\": \"cuda\", \"eval\": True,\n",
    "    \"render_process\": True, \"add_points\": False, \"extension\": \".png\",\n",
    "    \"llffhold\": 8\n",
    "})\n",
    "hyper = Namespace(**{\n",
    "    'net_width': 128, 'timebase_pe': 4, 'defor_depth': 0, 'posebase_pe': 10,\n",
    "    'scale_rotation_pe': 2, 'opacity_pe': 2, 'timenet_width': 64, 'timenet_output': 32,\n",
    "    'bounds': 1.6, 'plane_tv_weight': 0.0002, 'time_smoothness_weight': 0.001, 'l1_time_planes': 0.0001,\n",
    "    'kplanes_config': {\n",
    "        'grid_dimensions': 2, \n",
    "        'input_coordinate_dim': 4, \n",
    "        'output_coordinate_dim': 16, \n",
    "        'resolution': [64, 64, 64, 150]\n",
    "    }, 'multires': [1, 2],\n",
    "    'no_dx': False, 'no_grid': False, 'no_ds': False, 'no_dr': False, 'no_do': False, 'no_dshs': False,\n",
    "    'empty_voxel': False, 'grid_pe': 0, 'static_mlp': False, 'apply_rotation': False,\n",
    "})\n",
    "opt = Namespace(**{\n",
    "    'position_lr_init': 1.6e-4, 'position_lr_final': 1.6e-06, 'position_lr_delay_mult': 0.01, 'position_lr_max_steps': 20000,\n",
    "    'deformation_lr_init': 1.6e-4, 'deformation_lr_final': 1.6e-05, 'deformation_lr_delay_mult': 0.01,\n",
    "    'grid_lr_init': 1.6e-3, 'grid_lr_final': 1.6e-4, \n",
    "    'feature_lr': 0.0025, 'opacity_lr': 0.05, 'scaling_lr': 0.005, 'rotation_lr': 0.001, 'percent_dense': 0.01, \n",
    "})\n",
    "pipe = Namespace(**{\n",
    "    'convert_SHs_python': False,\n",
    "    'compute_cov3D_python': False,\n",
    "    'debug': False,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = Path(\"samples/ParallelDomain/scene_000000/colmap\")\n",
    "dataset_type = \"Kubric\"\n",
    "\n",
    "# scene_info = sceneLoadTypeCallbacks[dataset_type](datadir)\n",
    "cam_extrinsics = read_extrinsics_binary(os.path.join(datadir, \"sparse/0/images.bin\"))\n",
    "cam_intrinsics = read_intrinsics_binary(os.path.join(datadir, \"sparse/0/cameras.bin\"))\n",
    "cam_dict = {k:v.name for k,v in cam_extrinsics.items()}\n",
    "cam_ids = [k for k,v in cam_dict.items() if 'yaw-0' in v]\n",
    "\n",
    "train_cam_infos = multipleview_dataset_kubric(\n",
    "    cam_extrinsics=cam_extrinsics, cam_intrinsics=cam_intrinsics, \n",
    "    image_folder=os.path.join(datadir, \"../images\"), split=\"train\", cam_ids=cam_ids, \n",
    "    image_length=50, factor=3\n",
    ")\n",
    "train_cams = FourDGSdataset(train_cam_infos, None, dataset_type)\n",
    "\n",
    "# test_cam_infos = multipleview_dataset_kubric(\n",
    "#     cam_extrinsics=cam_extrinsics, cam_intrinsics=cam_intrinsics, \n",
    "#     image_folder=os.path.join(datadir, \"../images\"), split=\"test\", cam_ids=cam_ids\n",
    "# )\n",
    "# test_cams = FourDGSdataset(test_cam_infos, None, dataset_type)\n",
    "print(len(train_cams))\n",
    "print(train_cam_infos.image_paths)\n",
    "train_cam_infos[16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = Path(\"samples/parallel_scene_000000/colmap\")\n",
    "dataset_type = \"Kubric\"\n",
    "\n",
    "expname = Path(\"samples/parallel_scene_000000/outputs_v2\")\n",
    "expname.mkdir(parents=True, exist_ok=True)\n",
    "(expname / \"point_cloud\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "gaussians = GaussianModel(3, hyper)\n",
    "\n",
    "# scene_info = sceneLoadTypeCallbacks[dataset_type](datadir)\n",
    "cam_extrinsics = read_extrinsics_binary(os.path.join(datadir, \"sparse/0/images.bin\"))\n",
    "cam_intrinsics = read_intrinsics_binary(os.path.join(datadir, \"sparse/0/cameras.bin\"))\n",
    "cam_dict = {k:v.name for k,v in cam_extrinsics.items()}\n",
    "cam_ids = [k for k,v in cam_dict.items() if 'yaw-0' in v]\n",
    "\n",
    "total_cam_infos = multipleview_dataset_kubric(\n",
    "    cam_extrinsics=cam_extrinsics, cam_intrinsics=cam_intrinsics, \n",
    "    image_folder=os.path.join(datadir, \"../images\"), split=\"train\"\n",
    ")\n",
    "nerf_normalization = getNerfppNorm(format_infos(total_cam_infos,\"train\"))\n",
    "\n",
    "train_cam_infos = multipleview_dataset_kubric(\n",
    "    cam_extrinsics=cam_extrinsics, cam_intrinsics=cam_intrinsics, \n",
    "    image_folder=os.path.join(datadir, \"../images\"), split=\"train\", cam_ids=cam_ids\n",
    ")\n",
    "train_cams = FourDGSdataset(train_cam_infos, None, dataset_type)\n",
    "\n",
    "# test_cam_infos = multipleview_dataset_kubric(\n",
    "#     cam_extrinsics=cam_extrinsics, cam_intrinsics=cam_intrinsics, \n",
    "#     image_folder=os.path.join(datadir, \"../images\"), split=\"test\", cam_ids=cam_ids\n",
    "# )\n",
    "# test_cams = FourDGSdataset(test_cam_infos, None, dataset_type)\n",
    "print(len(train_cams))\n",
    "\n",
    "pcd = fetchPly(os.path.join(datadir, \"points3D_multipleview.ply\"))\n",
    "xyz_max, xyz_min = pcd.points.max(axis=0), pcd.points.min(axis=0)\n",
    "gaussians._deformation.deformation_net.set_aabb(xyz_max, xyz_min)\n",
    "gaussians.create_from_pcd(pcd, nerf_normalization[\"radius\"], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def render_imgs(model_path, gaussians, viewpoints, render_func, pipe, background, stage, iteration, dataset_type):\n",
    "    image_path = model_path / f\"{stage}_render/images\"\n",
    "    image_path.mkdir(parents=True, exist_ok=True)\n",
    "    for idx in range(len(viewpoints)):\n",
    "        render_pkg = render_func(viewpoints[idx], gaussians, pipe, background, stage=stage, cam_type=dataset_type)\n",
    "        image, depth, gt = render_pkg[\"render\"], render_pkg[\"depth\"], viewpoints[idx].original_image\n",
    "\n",
    "        gt_np = gt.permute(1,2,0).cpu().numpy()\n",
    "        image_np = image.permute(1, 2, 0).cpu().numpy()  # (H, W, 3)\n",
    "        depth_np = depth.permute(1, 2, 0).cpu().numpy()\n",
    "        depth_np /= depth_np.max()\n",
    "        depth_np = np.repeat(depth_np, 3, axis=2)\n",
    "        image_np = np.concatenate((gt_np, image_np, depth_np), axis=1)\n",
    "        image_with_labels = Image.fromarray((np.clip(image_np,0,1) * 255).astype('uint8'))  \n",
    "        image_with_labels.save(image_path / f\"{iteration}_{idx}.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussians.training_setup(opt)\n",
    "background = torch.tensor([1, 1, 1], dtype=torch.float32, device=\"cuda\")\n",
    "ema_loss_for_log = 0.0\n",
    "\n",
    "first_iter = 0\n",
    "final_iter = 3000\n",
    "progress_bar = tqdm(range(first_iter, final_iter), desc=\"Training progress\")\n",
    "first_iter += 1\n",
    "\n",
    "batch_size = 1\n",
    "print(\"data loading done\")\n",
    "viewpoint_stack_loader = DataLoader(train_cams, batch_size=batch_size, shuffle=True, num_workers=16, collate_fn=list)\n",
    "loader = iter(viewpoint_stack_loader)\n",
    "\n",
    "for iteration in range(first_iter, final_iter+1):        \n",
    "    gaussians.update_learning_rate(iteration)\n",
    "    if iteration % 1000 == 0:\n",
    "        gaussians.oneupSHdegree()\n",
    "\n",
    "    try:\n",
    "        viewpoint_cams = next(loader)\n",
    "    except StopIteration:\n",
    "        loader = iter(viewpoint_stack_loader)\n",
    "\n",
    "    images, gt_images, radii_list, visibility_filter_list, viewspace_point_tensor_list = [], [], [], [], []\n",
    "    for viewpoint_cam in viewpoint_cams:\n",
    "        render_pkg = render(\n",
    "            viewpoint_cam, gaussians, pipe, background, \n",
    "            stage='coarse', cam_type='MultipleView')\n",
    "        images.append(render_pkg[\"render\"].unsqueeze(0))\n",
    "        gt_images.append(viewpoint_cam.original_image.unsqueeze(0).cuda())\n",
    "        radii_list.append(render_pkg[\"radii\"].unsqueeze(0))\n",
    "        visibility_filter_list.append(render_pkg[\"visibility_filter\"].unsqueeze(0))\n",
    "        viewspace_point_tensor_list.append(render_pkg[\"viewspace_points\"])\n",
    "    image_tensor = torch.cat(images,0)\n",
    "    gt_image_tensor = torch.cat(gt_images,0)\n",
    "    radii = torch.cat(radii_list,0).max(dim=0).values\n",
    "    visibility_filter = torch.cat(visibility_filter_list).any(dim=0)\n",
    "\n",
    "    Ll1 = l1_loss(image_tensor, gt_image_tensor[:,:3,:,:])\n",
    "    loss = Ll1\n",
    "    loss.backward()\n",
    "\n",
    "    viewspace_point_tensor_grad = torch.zeros_like(render_pkg[\"viewspace_points\"])\n",
    "    for idx in range(0, len(viewspace_point_tensor_list)):\n",
    "        viewspace_point_tensor_grad = viewspace_point_tensor_grad + viewspace_point_tensor_list[idx].grad\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Progress bar\n",
    "        ema_loss_for_log = 0.4 * Ll1.item() + 0.6 * ema_loss_for_log\n",
    "        total_point = gaussians._xyz.shape[0]\n",
    "        if iteration % 10 == 0:\n",
    "            progress_bar.set_postfix({\"Loss\": f\"{ema_loss_for_log:.{7}f}\", \"point\":f\"{total_point}\"})\n",
    "            progress_bar.update(10)\n",
    "        if (iteration % 1000 == 0):\n",
    "            print(\"\\n[ITER {}] Saving Gaussians\".format(iteration))\n",
    "            (expname / f\"point_cloud/coarse_iteration_{iteration}\").mkdir(parents=True, exist_ok=True)\n",
    "            gaussians.save_ply(expname / f\"point_cloud/coarse_iteration_{iteration}/point_cloud.ply\")\n",
    "            gaussians.save_deformation(expname / f\"point_cloud/coarse_iteration_{iteration}\")\n",
    "        if iteration % 300 == 299:\n",
    "            # render_imgs(expname, gaussians, [ test_cams[iteration% len(test_cams)]], \n",
    "            #     render, pipe, background, \"coarse_test\", iteration, 'MultipleView')\n",
    "            render_imgs(expname, gaussians, [train_cams[iteration%len(train_cams)]], \n",
    "                render, pipe, background, \"coarse_train\", iteration, 'MultipleView')\n",
    "\n",
    "        # Densification\n",
    "        if iteration < 10000 :\n",
    "            gaussians.max_radii2D[visibility_filter] = torch.max(gaussians.max_radii2D[visibility_filter], radii[visibility_filter])\n",
    "            gaussians.add_densification_stats(viewspace_point_tensor_grad, visibility_filter)\n",
    "\n",
    "            size_threshold = 20 if iteration > 3000 else None\n",
    "            if iteration > 500 and iteration % 100 == 0 and gaussians.get_xyz.shape[0] < 360000:\n",
    "                gaussians.densify(0.0002, 0.005, nerf_normalization[\"radius\"], size_threshold, 5, 5, expname, iteration, \"coarse\")\n",
    "            if iteration > 500 and iteration % 100 == 0 and gaussians.get_xyz.shape[0] > 200000:\n",
    "                gaussians.prune(0.0002, 0.005, nerf_normalization[\"radius\"], size_threshold)\n",
    "            # if iteration % 3000 == 0:\n",
    "            #     gaussians.reset_opacity()\n",
    "\n",
    "        if iteration < 3000:\n",
    "            gaussians.optimizer.step()\n",
    "            gaussians.optimizer.zero_grad(set_to_none = True)\n",
    "        if (iteration in [1000, 2000, 3000]):\n",
    "            print(\"\\n[ITER {}] Saving Checkpoint\".format(iteration))\n",
    "            torch.save((gaussians.capture(), iteration), expname / f\"/chkpnt_coarse_{iteration}.pth\")\n",
    "progress_bar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "gaussians.training_setup(opt)\n",
    "background = torch.tensor([1, 1, 1], dtype=torch.float32, device=\"cuda\")\n",
    "ema_loss_for_log = 0.0\n",
    "\n",
    "first_iter = 0\n",
    "final_iter = 15000\n",
    "progress_bar = tqdm(range(first_iter, final_iter), desc=\"Training progress\")\n",
    "first_iter += 1\n",
    "\n",
    "batch_size = 1\n",
    "print(\"data loading done\")\n",
    "viewpoint_stack_loader = DataLoader(train_cams, batch_size=batch_size, shuffle=True, num_workers=16, collate_fn=list)\n",
    "loader = iter(viewpoint_stack_loader)\n",
    "\n",
    "for iteration in range(first_iter, final_iter+1):        \n",
    "    gaussians.update_learning_rate(iteration)\n",
    "    if iteration % 1000 == 0:\n",
    "        gaussians.oneupSHdegree()\n",
    "\n",
    "    try:\n",
    "        viewpoint_cams = next(loader)\n",
    "    except StopIteration:\n",
    "        loader = iter(viewpoint_stack_loader)\n",
    "\n",
    "    images, gt_images, radii_list, visibility_filter_list, viewspace_point_tensor_list = [], [], [], [], []\n",
    "    for viewpoint_cam in viewpoint_cams:\n",
    "        render_pkg = render(\n",
    "            viewpoint_cam, gaussians, pipe, background, \n",
    "            stage='fine', cam_type='MultipleView')\n",
    "        images.append(render_pkg[\"render\"].unsqueeze(0))\n",
    "        gt_images.append(viewpoint_cam.original_image.unsqueeze(0).cuda())\n",
    "        radii_list.append(render_pkg[\"radii\"].unsqueeze(0))\n",
    "        visibility_filter_list.append(render_pkg[\"visibility_filter\"].unsqueeze(0))\n",
    "        viewspace_point_tensor_list.append(render_pkg[\"viewspace_points\"])\n",
    "    image_tensor = torch.cat(images,0)\n",
    "    gt_image_tensor = torch.cat(gt_images,0)\n",
    "    radii = torch.cat(radii_list,0).max(dim=0).values\n",
    "    visibility_filter = torch.cat(visibility_filter_list).any(dim=0)\n",
    "\n",
    "    Ll1 = l1_loss(image_tensor, gt_image_tensor[:,:3,:,:])\n",
    "    tv_loss = gaussians.compute_regulation(hyper.time_smoothness_weight, hyper.l1_time_planes, hyper.plane_tv_weight)\n",
    "    loss = Ll1 + tv_loss\n",
    "    loss.backward()\n",
    "    \n",
    "    viewspace_point_tensor_grad = torch.zeros_like(render_pkg[\"viewspace_points\"])\n",
    "    for idx in range(0, len(viewspace_point_tensor_list)):\n",
    "        viewspace_point_tensor_grad = viewspace_point_tensor_grad + viewspace_point_tensor_list[idx].grad\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Progress bar\n",
    "        ema_loss_for_log = 0.4 * Ll1.item() + 0.6 * ema_loss_for_log\n",
    "        total_point = gaussians._xyz.shape[0]\n",
    "        if iteration % 10 == 0:\n",
    "            progress_bar.set_postfix({\"Loss\": f\"{ema_loss_for_log:.{7}f}\", \"point\":f\"{total_point}\"})\n",
    "            progress_bar.update(10)\n",
    "        if (iteration in [1000, 2000, 5000, 10000, 15000]):\n",
    "            print(\"\\n[ITER {}] Saving Gaussians\".format(iteration))\n",
    "            (expname / f\"point_cloud/fine_iteration_{iteration}\").mkdir(parents=True, exist_ok=True)\n",
    "            gaussians.save_ply(expname / f\"point_cloud/fine_iteration_{iteration}/point_cloud.ply\")\n",
    "            gaussians.save_deformation(expname / f\"point_cloud/fine_iteration_{iteration}\")\n",
    "        if iteration % 10 == 0:\n",
    "            render_imgs(expname, gaussians, [ test_cams[iteration% len(test_cams)]], \n",
    "                render, pipe, background, \"fine_test\", iteration, 'MultipleView')\n",
    "            render_imgs(expname, gaussians, [train_cams[iteration%len(train_cams)]], \n",
    "                render, pipe, background, \"fine_train\", iteration, 'MultipleView')\n",
    "\n",
    "        # Densification\n",
    "        if iteration < 10000 :\n",
    "            gaussians.max_radii2D[visibility_filter] = torch.max(gaussians.max_radii2D[visibility_filter], radii[visibility_filter])\n",
    "            gaussians.add_densification_stats(viewspace_point_tensor_grad, visibility_filter)\n",
    "\n",
    "            size_threshold = 20 if iteration > 15000 else None\n",
    "            if iteration > 500 and iteration % 100 == 0 and gaussians.get_xyz.shape[0] < 360000:\n",
    "                gaussians.densify(0.0002, 0.005, scene_info.nerf_normalization[\"radius\"], size_threshold, 5, 5, expname, iteration, \"fine\")\n",
    "            if iteration > 500 and iteration % 100 == 0 and gaussians.get_xyz.shape[0] > 200000:\n",
    "                gaussians.prune(0.0002, 0.005, scene_info.nerf_normalization[\"radius\"], size_threshold)\n",
    "            if iteration % 15000 == 0:\n",
    "                gaussians.reset_opacity()\n",
    "\n",
    "        if iteration < final_iter:\n",
    "            gaussians.optimizer.step()\n",
    "            gaussians.optimizer.zero_grad(set_to_none = True)\n",
    "        if (iteration in [1000, 2000, 5000, 10000, 15000]):\n",
    "            print(\"\\n[ITER {}] Saving Checkpoint\".format(iteration))\n",
    "            torch.save((gaussians.capture(), iteration), expname / f\"/chkpnt_fine_{iteration}.pth\")\n",
    "progress_bar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# render_pkg = render(\n",
    "#     viewpoint_cam, gaussians, pipe, background, \n",
    "#     stage='fine', cam_type='MultipleView')\n",
    "# def render(viewpoint_camera, pc : GaussianModel, pipe, bg_color : torch.Tensor, scaling_modifier = 1.0, override_color = None, stage=\"fine\", cam_type=None):\n",
    "\n",
    "screenspace_points = torch.zeros_like(gaussians.get_xyz, dtype=gaussians.get_xyz.dtype, requires_grad=True, device=\"cuda\") + 0\n",
    "means3D = gaussians.get_xyz\n",
    "raster_settings = GaussianRasterizationSettings(\n",
    "    image_height=int(viewpoint_cam.image_height),\n",
    "    image_width=int(viewpoint_cam.image_width),\n",
    "    tanfovx=math.tan(viewpoint_cam.FoVx * 0.5),\n",
    "    tanfovy=math.tan(viewpoint_cam.FoVy * 0.5),\n",
    "    bg=background,\n",
    "    scale_modifier=1.0,\n",
    "    viewmatrix=viewpoint_cam.world_view_transform.cuda(),\n",
    "    projmatrix=viewpoint_cam.full_proj_transform.cuda(),\n",
    "    sh_degree=gaussians.active_sh_degree,\n",
    "    campos=viewpoint_cam.camera_center.cuda(),\n",
    "    prefiltered=False,\n",
    "    debug=pipe.debug\n",
    ")\n",
    "time = torch.tensor(viewpoint_cam.time).to(means3D.device).repeat(means3D.shape[0],1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
