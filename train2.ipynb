{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '3,'\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "from pathlib import Path\n",
    "import random\n",
    "from argparse import ArgumentParser, Namespace\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import numpy as np\n",
    "np.set_printoptions(suppress=True)\n",
    "from PIL import Image\n",
    "import lpips\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms as T\n",
    "\n",
    "from gaussian_renderer import render\n",
    "from scene import Scene, GaussianModel, colmap_loader\n",
    "from scene.cameras import Camera\n",
    "from scene.colmap_loader import read_extrinsics_binary, read_intrinsics_binary\n",
    "from scene.colmap_loader import qvec2rotmat, rotmat2qvec\n",
    "from scene.dataset import FourDGSdataset\n",
    "from scene.dataset_readers import sceneLoadTypeCallbacks, format_infos, getNerfppNorm, fetchPly, SceneInfo\n",
    "from utils.graphics_utils import focal2fov\n",
    "from utils.loss_utils import l1_loss\n",
    "\n",
    "def setup_seed(seed):\n",
    "     torch.manual_seed(seed)\n",
    "     torch.cuda.manual_seed_all(seed)\n",
    "     np.random.seed(seed)\n",
    "     random.seed(seed)\n",
    "     torch.backends.cudnn.deterministic = True\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "setup_seed(6666)\n",
    "# torch.cuda.set_device(0)\n",
    "# torch.autograd.set_detect_anomaly(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper = Namespace(**{\n",
    "    'net_width': 128, 'timebase_pe': 4, 'defor_depth': 0, 'posebase_pe': 10,\n",
    "    'scale_rotation_pe': 2, 'opacity_pe': 2, 'timenet_width': 64, 'timenet_output': 32,\n",
    "    'bounds': 1.6, 'plane_tv_weight': 0.0002, 'time_smoothness_weight': 0.001, 'l1_time_planes': 0.0001,\n",
    "    'kplanes_config': {\n",
    "        'grid_dimensions': 2, \n",
    "        'input_coordinate_dim': 4, \n",
    "        'output_coordinate_dim': 16, \n",
    "        'resolution': [64, 64, 64, 150]\n",
    "    }, 'multires': [1, 2],\n",
    "    'no_dx': False, 'no_grid': False, 'no_ds': False, 'no_dr': False, 'no_do': False, 'no_dshs': False,\n",
    "    'empty_voxel': False, 'grid_pe': 0, 'static_mlp': False, 'apply_rotation': False,\n",
    "})\n",
    "opt = Namespace(**{\n",
    "    'position_lr_init': 1.6e-4, 'position_lr_final': 1.6e-06, 'position_lr_delay_mult': 0.01, 'position_lr_max_steps': 20000,\n",
    "    'deformation_lr_init': 1.6e-4, 'deformation_lr_final': 1.6e-05, 'deformation_lr_delay_mult': 0.01,\n",
    "    'grid_lr_init': 1.6e-3, 'grid_lr_final': 1.6e-4, \n",
    "    'feature_lr': 0.0025, 'opacity_lr': 0.05, 'scaling_lr': 0.005, 'rotation_lr': 0.001, 'percent_dense': 0.01, \n",
    "})\n",
    "pipe = Namespace(**{\n",
    "    'convert_SHs_python': False,\n",
    "    'compute_cov3D_python': False,\n",
    "    'debug': False,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = Path(\"kubric4d/test/scn02902\")\n",
    "\n",
    "cameras = sorted(list(root_dir.glob(\"*.json\")), key=lambda x: int(x.stem.split(\"_v\")[-1]))\n",
    "# for cam_path in cameras:\n",
    "cam_path = cameras[4]\n",
    "name = cam_path.stem.replace(root_dir.stem, \"frames\")\n",
    "metadata = json.loads(cam_path.read_bytes())\n",
    "W, H = metadata['scene']['resolution']\n",
    "\n",
    "K = np.abs(metadata['camera']['K'])\n",
    "K = torch.tensor(K, dtype=torch.float32)\n",
    "K[0, :] *= W\n",
    "K[1, :] *= H\n",
    "focal = K[0,0]\n",
    "# focal = 32.0\n",
    "princp = K[0,2], K[1,2]\n",
    "\n",
    "img_paths = sorted(list(root_dir.glob(f\"{name}/rgba_*.png\")))\n",
    "img_path = img_paths[0]\n",
    "\n",
    "t = int(img_path.stem.split(\"_\")[-1])\n",
    "qvec = np.array(metadata['camera']['quaternions'][t])\n",
    "T = np.array(metadata['camera']['positions'][t])\n",
    "R = qvec2rotmat(qvec)\n",
    "\n",
    "R = R @ np.diag([1.0, -1.0, -1.0])\n",
    "R = -R.T\n",
    "R[:,0] *= -1.0\n",
    "T = -T\n",
    "T = -np.matmul(R,T)\n",
    "R = R.T\n",
    "print(R)\n",
    "print(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class multipleview_dataset_kubric(Dataset):\n",
    "    def __init__(self, cam_extrinsics, cam_intrinsics, cam_folder, split):\n",
    "        key = list(cam_intrinsics.keys())[0]\n",
    "        self.focal = [cam_intrinsics[key].params[0], cam_intrinsics[key].params[0]]\n",
    "        height=cam_intrinsics[key].height\n",
    "        width=cam_intrinsics[key].width\n",
    "        self.FovY = focal2fov(self.focal[0], height)\n",
    "        self.FovX = focal2fov(self.focal[0], width)\n",
    "        self.transform = T.ToTensor()\n",
    "\n",
    "        self.image_paths, self.image_poses, self.image_times= self.load_images_path(cam_folder, cam_extrinsics, split)\n",
    "\n",
    "    def load_images_path(self, cam_folder, cam_extrinsics, split=\"train\", image_length = 60, factor=4):\n",
    "        image_folder = os.path.join(cam_folder, \"images\")\n",
    "        image_range = list(range(0, image_length, factor)) if split == \"train\" else list(range(0, image_length, factor*5))\n",
    "\n",
    "        image_paths, image_poses, image_times = [], [], []\n",
    "        for idx, key in enumerate(cam_extrinsics):\n",
    "            extr = cam_extrinsics[key]\n",
    "            R = np.transpose(qvec2rotmat(extr.qvec))\n",
    "            T = np.array(extr.tvec)\n",
    "            image_path = os.path.join(image_folder, extr.name)\n",
    "            time = int(extr.name.split(\".\")[0].split(\"_\")[-1])\n",
    "            if time in image_range:\n",
    "                image_paths.append(image_path)\n",
    "                image_poses.append((R,T))\n",
    "                image_times.append(float(time/image_length))\n",
    "        return image_paths, image_poses, image_times\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img = self.transform(Image.open(self.image_paths[index]))\n",
    "        return img, self.image_poses[index], self.image_times[index]\n",
    "    \n",
    "    def load_pose(self,index):\n",
    "        return self.image_poses[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = Path(\"samples/scn02902/colmap\")\n",
    "dataset_type = \"Kubric\"\n",
    "\n",
    "expname = Path(\"samples/scn02902/outputs_2\")\n",
    "expname.mkdir(parents=True, exist_ok=True)\n",
    "(expname / \"point_cloud\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "gaussians = GaussianModel(3, hyper)\n",
    "\n",
    "scene_info = sceneLoadTypeCallbacks[dataset_type](datadir)\n",
    "        \n",
    "train_cams = FourDGSdataset(scene_info.train_cameras, None, \"\")\n",
    "test_cams = FourDGSdataset(scene_info.test_cameras, None, \"\")\n",
    "# video_cams = FourDGSdataset(scene_info.video_cameras)\n",
    "\n",
    "xyz_max, xyz_min = scene_info.point_cloud.points.max(axis=0), scene_info.point_cloud.points.min(axis=0)\n",
    "gaussians._deformation.deformation_net.set_aabb(xyz_max, xyz_min)\n",
    "gaussians.create_from_pcd(scene_info.point_cloud, scene_info.nerf_normalization[\"radius\"], scene_info.maxtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def render_imgs(model_path, gaussians, viewpoints, render_func, pipe, background, stage, iteration, dataset_type):\n",
    "    image_path = model_path / f\"{stage}_render/images\"\n",
    "    image_path.mkdir(parents=True, exist_ok=True)\n",
    "    for idx in range(len(viewpoints)):\n",
    "        render_pkg = render_func(viewpoints[idx], gaussians, pipe, background, stage=stage, cam_type=dataset_type)\n",
    "        image, depth, gt = render_pkg[\"render\"], render_pkg[\"depth\"], viewpoints[idx].original_image\n",
    "\n",
    "        gt_np = gt.permute(1,2,0).cpu().numpy()\n",
    "        image_np = image.permute(1, 2, 0).cpu().numpy()  # (H, W, 3)\n",
    "        depth_np = depth.permute(1, 2, 0).cpu().numpy()\n",
    "        depth_np /= depth_np.max()\n",
    "        depth_np = np.repeat(depth_np, 3, axis=2)\n",
    "        image_np = np.concatenate((gt_np, image_np, depth_np), axis=1)\n",
    "        image_with_labels = Image.fromarray((np.clip(image_np,0,1) * 255).astype('uint8'))  \n",
    "        image_with_labels.save(image_path / f\"{iteration}_{idx}.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussians.training_setup(opt)\n",
    "background = torch.tensor([1, 1, 1], dtype=torch.float32, device=\"cuda\")\n",
    "ema_loss_for_log = 0.0\n",
    "\n",
    "first_iter = 0\n",
    "final_iter = 3000\n",
    "progress_bar = tqdm(range(first_iter, final_iter), desc=\"Training progress\")\n",
    "first_iter += 1\n",
    "\n",
    "batch_size = 1\n",
    "print(\"data loading done\")\n",
    "viewpoint_stack_loader = DataLoader(train_cams, batch_size=batch_size, shuffle=True, num_workers=16, collate_fn=list)\n",
    "loader = iter(viewpoint_stack_loader)\n",
    "\n",
    "for iteration in range(first_iter, final_iter+1):        \n",
    "    gaussians.update_learning_rate(iteration)\n",
    "    if iteration % 1000 == 0:\n",
    "        gaussians.oneupSHdegree()\n",
    "\n",
    "    try:\n",
    "        viewpoint_cams = next(loader)\n",
    "    except StopIteration:\n",
    "        loader = iter(viewpoint_stack_loader)\n",
    "\n",
    "    images, gt_images, radii_list, visibility_filter_list, viewspace_point_tensor_list = [], [], [], [], []\n",
    "    for viewpoint_cam in viewpoint_cams:\n",
    "        render_pkg = render(viewpoint_cam, gaussians, pipe, background, \n",
    "            stage='coarse', cam_type='MultipleView')\n",
    "        images.append(render_pkg[\"render\"].unsqueeze(0))\n",
    "        gt_images.append(viewpoint_cam.original_image.unsqueeze(0).cuda())\n",
    "        radii_list.append(render_pkg[\"radii\"].unsqueeze(0))\n",
    "        visibility_filter_list.append(render_pkg[\"visibility_filter\"].unsqueeze(0))\n",
    "        viewspace_point_tensor_list.append(render_pkg[\"viewspace_points\"])\n",
    "    image_tensor = torch.cat(images,0)\n",
    "    gt_image_tensor = torch.cat(gt_images,0)\n",
    "    radii = torch.cat(radii_list,0).max(dim=0).values\n",
    "    visibility_filter = torch.cat(visibility_filter_list).any(dim=0)\n",
    "\n",
    "    Ll1 = l1_loss(image_tensor, gt_image_tensor[:,:3,:,:])\n",
    "    loss = Ll1\n",
    "    loss.backward()\n",
    "\n",
    "    viewspace_point_tensor_grad = torch.zeros_like(render_pkg[\"viewspace_points\"])\n",
    "    for idx in range(0, len(viewspace_point_tensor_list)):\n",
    "        viewspace_point_tensor_grad = viewspace_point_tensor_grad + viewspace_point_tensor_list[idx].grad\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Progress bar\n",
    "        ema_loss_for_log = 0.4 * Ll1.item() + 0.6 * ema_loss_for_log\n",
    "        total_point = gaussians._xyz.shape[0]\n",
    "        if iteration % 10 == 0:\n",
    "            progress_bar.set_postfix({\"Loss\": f\"{ema_loss_for_log:.{7}f}\", \"point\":f\"{total_point}\"})\n",
    "            progress_bar.update(10)\n",
    "        if (iteration % 1000 == 0):\n",
    "            print(\"\\n[ITER {}] Saving Gaussians\".format(iteration))\n",
    "            (expname / f\"point_cloud/coarse_iteration_{iteration}\").mkdir(parents=True, exist_ok=True)\n",
    "            gaussians.save_ply(expname / f\"point_cloud/coarse_iteration_{iteration}/point_cloud.ply\")\n",
    "            gaussians.save_deformation(expname / f\"point_cloud/coarse_iteration_{iteration}\")\n",
    "        if iteration % 10 == 0:\n",
    "            render_imgs(expname, gaussians, [ test_cams[iteration% len(test_cams)]], \n",
    "                render, pipe, background, \"coarse_test\", iteration, 'MultipleView')\n",
    "            render_imgs(expname, gaussians, [train_cams[iteration%len(train_cams)]], \n",
    "                render, pipe, background, \"coarse_train\", iteration, 'MultipleView')\n",
    "\n",
    "        # Densification\n",
    "        if iteration < 10000 :\n",
    "            gaussians.max_radii2D[visibility_filter] = torch.max(gaussians.max_radii2D[visibility_filter], radii[visibility_filter])\n",
    "            gaussians.add_densification_stats(viewspace_point_tensor_grad, visibility_filter)\n",
    "\n",
    "            size_threshold = 20 if iteration > 3000 else None\n",
    "            if iteration > 500 and iteration % 100 == 0 and gaussians.get_xyz.shape[0] < 360000:\n",
    "                gaussians.densify(0.0002, 0.005, scene_info.nerf_normalization[\"radius\"], size_threshold, 5, 5, expname, iteration, \"coarse\")\n",
    "            if iteration > 500 and iteration % 100 == 0 and gaussians.get_xyz.shape[0] > 200000:\n",
    "                gaussians.prune(0.0002, 0.005, scene_info.nerf_normalization[\"radius\"], size_threshold)\n",
    "            # if iteration % 3000 == 0:\n",
    "            #     gaussians.reset_opacity()\n",
    "\n",
    "        if iteration < 3000:\n",
    "            gaussians.optimizer.step()\n",
    "            gaussians.optimizer.zero_grad(set_to_none = True)\n",
    "        if (iteration in [1000, 2000, 3000]):\n",
    "            print(\"\\n[ITER {}] Saving Checkpoint\".format(iteration))\n",
    "            torch.save((gaussians.capture(), iteration), expname / f\"/chkpnt_coarse_{iteration}.pth\")\n",
    "progress_bar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "gaussians.training_setup(opt)\n",
    "background = torch.tensor([1, 1, 1], dtype=torch.float32, device=\"cuda\")\n",
    "ema_loss_for_log = 0.0\n",
    "\n",
    "first_iter = 0\n",
    "final_iter = 15000\n",
    "progress_bar = tqdm(range(first_iter, final_iter), desc=\"Training progress\")\n",
    "first_iter += 1\n",
    "\n",
    "batch_size = 1\n",
    "print(\"data loading done\")\n",
    "viewpoint_stack_loader = DataLoader(train_cams, batch_size=batch_size, shuffle=True, num_workers=16, collate_fn=list)\n",
    "loader = iter(viewpoint_stack_loader)\n",
    "\n",
    "for iteration in range(first_iter, final_iter+1):        \n",
    "    gaussians.update_learning_rate(iteration)\n",
    "    if iteration % 1000 == 0:\n",
    "        gaussians.oneupSHdegree()\n",
    "\n",
    "    try:\n",
    "        viewpoint_cams = next(loader)\n",
    "    except StopIteration:\n",
    "        loader = iter(viewpoint_stack_loader)\n",
    "\n",
    "    images, gt_images, radii_list, visibility_filter_list, viewspace_point_tensor_list = [], [], [], [], []\n",
    "    for viewpoint_cam in viewpoint_cams:\n",
    "        render_pkg = render(\n",
    "            viewpoint_cam, gaussians, pipe, background, \n",
    "            stage='fine', cam_type='MultipleView')\n",
    "        images.append(render_pkg[\"render\"].unsqueeze(0))\n",
    "        gt_images.append(viewpoint_cam.original_image.unsqueeze(0).cuda())\n",
    "        radii_list.append(render_pkg[\"radii\"].unsqueeze(0))\n",
    "        visibility_filter_list.append(render_pkg[\"visibility_filter\"].unsqueeze(0))\n",
    "        viewspace_point_tensor_list.append(render_pkg[\"viewspace_points\"])\n",
    "    image_tensor = torch.cat(images,0)\n",
    "    gt_image_tensor = torch.cat(gt_images,0)\n",
    "    radii = torch.cat(radii_list,0).max(dim=0).values\n",
    "    visibility_filter = torch.cat(visibility_filter_list).any(dim=0)\n",
    "\n",
    "    Ll1 = l1_loss(image_tensor, gt_image_tensor[:,:3,:,:])\n",
    "    tv_loss = gaussians.compute_regulation(hyper.time_smoothness_weight, hyper.l1_time_planes, hyper.plane_tv_weight)\n",
    "    loss = Ll1 + tv_loss\n",
    "    loss.backward()\n",
    "    viewspace_point_tensor_grad = torch.zeros_like(render_pkg[\"viewspace_points\"])\n",
    "    for idx in range(0, len(viewspace_point_tensor_list)):\n",
    "        viewspace_point_tensor_grad = viewspace_point_tensor_grad + viewspace_point_tensor_list[idx].grad\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Progress bar\n",
    "        ema_loss_for_log = 0.4 * Ll1.item() + 0.6 * ema_loss_for_log\n",
    "        total_point = gaussians._xyz.shape[0]\n",
    "        if iteration % 10 == 0:\n",
    "            progress_bar.set_postfix({\"Loss\": f\"{ema_loss_for_log:.{7}f}\", \"point\":f\"{total_point}\"})\n",
    "            progress_bar.update(10)\n",
    "        if (iteration in [1000, 2000, 3000]):\n",
    "            print(\"\\n[ITER {}] Saving Gaussians\".format(iteration))\n",
    "            (expname / f\"point_cloud/fine_iteration_{iteration}\").mkdir(parents=True, exist_ok=True)\n",
    "            gaussians.save_ply(expname / f\"point_cloud/fine_iteration_{iteration}/point_cloud.ply\")\n",
    "            gaussians.save_deformation(expname / f\"point_cloud/fine_iteration_{iteration}\")\n",
    "        if iteration % 10 == 0:\n",
    "            render_imgs(expname, gaussians, [ test_cams[iteration% len(test_cams)]], \n",
    "                render, pipe, background, \"fine_test\", iteration, 'MultipleView')\n",
    "            render_imgs(expname, gaussians, [train_cams[iteration%len(train_cams)]], \n",
    "                render, pipe, background, \"fine_train\", iteration, 'MultipleView')\n",
    "\n",
    "        # Densification\n",
    "        if iteration < 10000 :\n",
    "            gaussians.max_radii2D[visibility_filter] = torch.max(gaussians.max_radii2D[visibility_filter], radii[visibility_filter])\n",
    "            gaussians.add_densification_stats(viewspace_point_tensor_grad, visibility_filter)\n",
    "\n",
    "            size_threshold = 20 if iteration > 3000 else None\n",
    "            if iteration > 500 and iteration % 100 == 0 and gaussians.get_xyz.shape[0] < 360000:\n",
    "                gaussians.densify(0.0002, 0.005, scene_info.nerf_normalization[\"radius\"], size_threshold, 5, 5, expname, iteration, \"fine\")\n",
    "            if iteration > 500 and iteration % 100 == 0 and gaussians.get_xyz.shape[0] > 200000:\n",
    "                gaussians.prune(0.0002, 0.005, scene_info.nerf_normalization[\"radius\"], size_threshold)\n",
    "            if iteration % 3000 == 0:\n",
    "                gaussians.reset_opacity()\n",
    "\n",
    "        if iteration < 3000:\n",
    "            gaussians.optimizer.step()\n",
    "            gaussians.optimizer.zero_grad(set_to_none = True)\n",
    "        if (iteration in [1000, 2000, 3000]):\n",
    "            print(\"\\n[ITER {}] Saving Checkpoint\".format(iteration))\n",
    "            torch.save((gaussians.capture(), iteration), expname / f\"/chkpnt_fine_{iteration}.pth\")\n",
    "progress_bar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# render_pkg = render(\n",
    "#     viewpoint_cam, gaussians, pipe, background, \n",
    "#     stage='fine', cam_type='MultipleView')\n",
    "# def render(viewpoint_camera, pc : GaussianModel, pipe, bg_color : torch.Tensor, scaling_modifier = 1.0, override_color = None, stage=\"fine\", cam_type=None):\n",
    "\n",
    "screenspace_points = torch.zeros_like(gaussians.get_xyz, dtype=gaussians.get_xyz.dtype, requires_grad=True, device=\"cuda\") + 0\n",
    "means3D = gaussians.get_xyz\n",
    "raster_settings = GaussianRasterizationSettings(\n",
    "    image_height=int(viewpoint_cam.image_height),\n",
    "    image_width=int(viewpoint_cam.image_width),\n",
    "    tanfovx=math.tan(viewpoint_cam.FoVx * 0.5),\n",
    "    tanfovy=math.tan(viewpoint_cam.FoVy * 0.5),\n",
    "    bg=background,\n",
    "    scale_modifier=1.0,\n",
    "    viewmatrix=viewpoint_cam.world_view_transform.cuda(),\n",
    "    projmatrix=viewpoint_cam.full_proj_transform.cuda(),\n",
    "    sh_degree=gaussians.active_sh_degree,\n",
    "    campos=viewpoint_cam.camera_center.cuda(),\n",
    "    prefiltered=False,\n",
    "    debug=pipe.debug\n",
    ")\n",
    "time = torch.tensor(viewpoint_cam.time).to(means3D.device).repeat(means3D.shape[0],1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
